{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from starreco.model import *\n",
    "#from starreco.data import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/kyleong/anaconda3/envs/starreco/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 55    \n",
      "1 | decoder | Sequential | 60    \n",
      "---------------------------------------\n",
      "115       Trainable params\n",
      "0         Non-trainable params\n",
      "115       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 4/4 [00:00<00:00, 18.62it/s, loss=1.31e+04, train_loss_step=1.52e+4, train_loss_epoch=1.31e+4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_x = torch.FloatTensor(3760,10).random_(0, 5)\n",
    "user_train_ds = TensorDataset(user_x, user_x)\n",
    "user_train_dl = DataLoader(user_train_ds, batch_size = 1024, num_workers = 8)\n",
    "\n",
    "user_mda = mDA(10, 5)\n",
    "pl.Trainer(gpus = 1, max_epochs = 500, progress_bar_refresh_rate = 50, logger = False)\\\n",
    ".fit(user_mda, user_train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 40    \n",
      "1 | decoder | Sequential | 42    \n",
      "---------------------------------------\n",
      "82        Trainable params\n",
      "0         Non-trainable params\n",
      "82        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 6/6 [00:00<00:00, 24.80it/s, loss=3.24e+03, train_loss_step=3.38e+3, train_loss_epoch=3.29e+3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_x = torch.FloatTensor(6040,7).random_(0, 5)\n",
    "item_train_ds = TensorDataset(item_x, item_x)\n",
    "item_train_dl = DataLoader(item_train_ds, batch_size = 1024, num_workers = 8)\n",
    "\n",
    "item_mda = mDA(7, 5)\n",
    "pl.Trainer(gpus = 1, max_epochs = 500, progress_bar_refresh_rate = 50, logger = False)\\\n",
    ".fit(item_mda, item_train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.weight Parameter containing:\n",
      "tensor([[-2.7126e+00,  1.1661e+00, -1.2689e+00, -2.5834e+00,  3.9964e-01],\n",
      "        [ 1.2861e+00, -2.0164e+00, -1.6569e+00,  1.3712e+00, -2.5131e+00],\n",
      "        [-5.6672e-01, -1.6256e+00, -1.7292e+00,  1.2545e+00,  1.4366e+00],\n",
      "        [-2.5882e+00, -1.5447e+00, -8.6207e-01,  4.4134e-01, -1.1240e+00],\n",
      "        [ 1.1901e+00,  3.0691e-01,  1.4074e+00,  1.2434e+00,  6.7008e-01],\n",
      "        [ 9.7806e-02,  1.6562e+00, -1.3372e+00, -7.7548e-01,  6.4279e-01],\n",
      "        [-2.6087e+00, -1.7731e-03,  2.3472e-01, -9.3453e-01,  1.0998e+00],\n",
      "        [ 2.7469e-01, -2.7183e+00,  1.7429e+00, -1.9194e+00, -2.5782e+00],\n",
      "        [ 6.8437e-01,  5.0495e-01, -1.8593e+00, -2.2644e+00, -1.2176e+00],\n",
      "        [-1.5124e+00,  3.3837e-01,  1.1705e+00, -2.6118e+00,  7.3654e-01]],\n",
      "       requires_grad=True)\n",
      "encoder.0.bias Parameter containing:\n",
      "tensor([0.4306, 0.3943, 0.4182, 0.4022, 0.3303], requires_grad=True)\n",
      "decoder.0.weight Parameter containing:\n",
      "tensor([[-2.5179,  1.1604, -0.3327, -2.0690,  1.3157,  0.3400, -2.4214,  0.3816,\n",
      "          0.6037, -1.2411],\n",
      "        [ 1.1549, -1.7554, -1.5806, -0.1982,  0.4076,  1.6696,  0.0608, -2.5154,\n",
      "          0.5243,  0.4187],\n",
      "        [-1.0577, -1.4196, -1.5565, -0.1372,  1.5106, -1.0905,  0.3921,  1.4680,\n",
      "         -1.3049,  1.2565],\n",
      "        [-2.3527,  1.2253,  1.3348,  0.1889,  1.3851, -0.4801, -0.6714, -1.6579,\n",
      "         -2.0602, -2.3657],\n",
      "        [ 0.4396, -2.3096,  1.4181, -0.0708,  0.7966,  0.6988,  1.1439, -2.4533,\n",
      "         -0.6606,  0.8089]])\n",
      "decoder.0.bias Parameter containing:\n",
      "tensor([0.5314, 1.5771, 0.4055, 2.1827, 0.3482, 0.3670, 0.4178, 1.2394, 2.0534,\n",
      "        0.3931])\n",
      "---\n",
      "encoder.0.weight Parameter containing:\n",
      "tensor([[-3.0148, -1.7045,  0.9834,  1.0479,  1.5072],\n",
      "        [-1.3784, -3.0875,  1.9530, -0.0048, -0.1739],\n",
      "        [-3.1733, -1.0932, -1.4990,  0.8881,  1.3216],\n",
      "        [-2.7231, -0.5544, -1.0964, -0.9070, -2.5802],\n",
      "        [-0.1765,  1.3244, -1.6296, -0.4039, -2.1363],\n",
      "        [ 0.0069, -2.6289, -1.5928, -2.7875,  0.6516],\n",
      "        [ 1.5116,  0.2662, -0.2802, -0.7070, -3.3495]], requires_grad=True)\n",
      "encoder.0.bias Parameter containing:\n",
      "tensor([0.2756, 0.2128, 0.1719, 0.3072, 0.0450], requires_grad=True)\n",
      "decoder.0.weight Parameter containing:\n",
      "tensor([[-2.8812, -1.1204, -2.9408, -2.5082, -0.0932,  0.1742,  1.4747],\n",
      "        [-1.4787, -2.8363, -0.7737, -0.1328,  1.3204, -2.6357,  0.2290],\n",
      "        [ 1.1080,  1.9897, -1.3556, -0.1799, -0.3645, -1.1752, -0.0077],\n",
      "        [ 1.0971,  0.0900,  0.9784, -0.2670,  0.0406, -2.8168, -0.1874],\n",
      "        [ 1.6156,  0.1473,  1.3825, -0.3866, -0.3022,  0.4903, -1.5379]])\n",
      "decoder.0.bias Parameter containing:\n",
      "tensor([0.2884, 0.6470, 0.7973, 2.2324, 2.1754, 2.2360, 2.1867])\n",
      "---\n",
      "user_mda.encoder.0.weight Parameter containing:\n",
      "tensor([[-2.7126e+00,  1.1661e+00, -1.2689e+00, -2.5834e+00,  3.9964e-01],\n",
      "        [ 1.2861e+00, -2.0164e+00, -1.6569e+00,  1.3712e+00, -2.5131e+00],\n",
      "        [-5.6672e-01, -1.6256e+00, -1.7292e+00,  1.2545e+00,  1.4366e+00],\n",
      "        [-2.5882e+00, -1.5447e+00, -8.6207e-01,  4.4134e-01, -1.1240e+00],\n",
      "        [ 1.1901e+00,  3.0691e-01,  1.4074e+00,  1.2434e+00,  6.7008e-01],\n",
      "        [ 9.7806e-02,  1.6562e+00, -1.3372e+00, -7.7548e-01,  6.4279e-01],\n",
      "        [-2.6087e+00, -1.7731e-03,  2.3472e-01, -9.3453e-01,  1.0998e+00],\n",
      "        [ 2.7469e-01, -2.7183e+00,  1.7429e+00, -1.9194e+00, -2.5782e+00],\n",
      "        [ 6.8437e-01,  5.0495e-01, -1.8593e+00, -2.2644e+00, -1.2176e+00],\n",
      "        [-1.5124e+00,  3.3837e-01,  1.1705e+00, -2.6118e+00,  7.3654e-01]],\n",
      "       requires_grad=True)\n",
      "user_mda.encoder.0.bias Parameter containing:\n",
      "tensor([0.4306, 0.3943, 0.4182, 0.4022, 0.3303], requires_grad=True)\n",
      "user_mda.decoder.0.weight Parameter containing:\n",
      "tensor([[-2.5179,  1.1604, -0.3327, -2.0690,  1.3157,  0.3400, -2.4214,  0.3816,\n",
      "          0.6037, -1.2411],\n",
      "        [ 1.1549, -1.7554, -1.5806, -0.1982,  0.4076,  1.6696,  0.0608, -2.5154,\n",
      "          0.5243,  0.4187],\n",
      "        [-1.0577, -1.4196, -1.5565, -0.1372,  1.5106, -1.0905,  0.3921,  1.4680,\n",
      "         -1.3049,  1.2565],\n",
      "        [-2.3527,  1.2253,  1.3348,  0.1889,  1.3851, -0.4801, -0.6714, -1.6579,\n",
      "         -2.0602, -2.3657],\n",
      "        [ 0.4396, -2.3096,  1.4181, -0.0708,  0.7966,  0.6988,  1.1439, -2.4533,\n",
      "         -0.6606,  0.8089]])\n",
      "user_mda.decoder.0.bias Parameter containing:\n",
      "tensor([0.5314, 1.5771, 0.4055, 2.1827, 0.3482, 0.3670, 0.4178, 1.2394, 2.0534,\n",
      "        0.3931])\n",
      "item_mda.encoder.0.weight Parameter containing:\n",
      "tensor([[-3.0148, -1.7045,  0.9834,  1.0479,  1.5072],\n",
      "        [-1.3784, -3.0875,  1.9530, -0.0048, -0.1739],\n",
      "        [-3.1733, -1.0932, -1.4990,  0.8881,  1.3216],\n",
      "        [-2.7231, -0.5544, -1.0964, -0.9070, -2.5802],\n",
      "        [-0.1765,  1.3244, -1.6296, -0.4039, -2.1363],\n",
      "        [ 0.0069, -2.6289, -1.5928, -2.7875,  0.6516],\n",
      "        [ 1.5116,  0.2662, -0.2802, -0.7070, -3.3495]], requires_grad=True)\n",
      "item_mda.encoder.0.bias Parameter containing:\n",
      "tensor([0.2756, 0.2128, 0.1719, 0.3072, 0.0450], requires_grad=True)\n",
      "item_mda.decoder.0.weight Parameter containing:\n",
      "tensor([[-2.8812, -1.1204, -2.9408, -2.5082, -0.0932,  0.1742,  1.4747],\n",
      "        [-1.4787, -2.8363, -0.7737, -0.1328,  1.3204, -2.6357,  0.2290],\n",
      "        [ 1.1080,  1.9897, -1.3556, -0.1799, -0.3645, -1.1752, -0.0077],\n",
      "        [ 1.0971,  0.0900,  0.9784, -0.2670,  0.0406, -2.8168, -0.1874],\n",
      "        [ 1.6156,  0.1473,  1.3825, -0.3866, -0.3022,  0.4903, -1.5379]])\n",
      "item_mda.decoder.0.bias Parameter containing:\n",
      "tensor([0.2884, 0.6470, 0.7973, 2.2324, 2.1754, 2.2360, 2.1867])\n"
     ]
    }
   ],
   "source": [
    "mdacf = mDACF(user_mda, item_mda, \n",
    "              weight_decay = 0) # Weight decay > 0 will updates freezed weights\n",
    "\n",
    "for name, param in user_mda.named_parameters():\n",
    "    print(name, param)\n",
    "print(\"---\")\n",
    "for name, param in item_mda.named_parameters():\n",
    "    print(name, param)\n",
    "print(\"---\")\n",
    "for name, param in mdacf.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name     | Type | Params\n",
      "----------------------------------\n",
      "0 | user_mda | mDA  | 115   \n",
      "1 | item_mda | mDA  | 82    \n",
      "----------------------------------\n",
      "95        Trainable params\n",
      "102       Non-trainable params\n",
      "197       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 977/977 [00:06<00:00, 150.43it/s, loss=2, train_loss_step=2.050, train_loss_epoch=2.000]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.FloatTensor(1000000,17).random_(0, 5)\n",
    "y = torch.FloatTensor(1000000).random_(1,6)\n",
    "train_ds = TensorDataset(X,y)\n",
    "train_dl = DataLoader(train_ds, batch_size = 1024, num_workers = 8)\n",
    "\n",
    "pl.Trainer(gpus = 1, max_epochs = 100, progress_bar_refresh_rate = 50, logger = False)\\\n",
    ".fit(mdacf, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.weight Parameter containing:\n",
      "tensor([[-4.2298e+00,  2.8513e-01, -1.4298e+00,  4.3226e-04,  2.6061e-01],\n",
      "        [ 7.8817e-01, -1.0308e+00, -2.0594e+00, -1.8189e-03, -2.7300e+00],\n",
      "        [-1.3828e+00, -1.9681e+00, -1.7320e+00,  4.2058e-03,  4.7564e-01],\n",
      "        [-2.0084e+00, -9.7755e-01, -8.2517e-01, -4.5225e-05, -1.6357e+00],\n",
      "        [ 6.5722e-01, -4.5356e-02,  3.7121e-01, -1.0810e-03, -1.5999e-01],\n",
      "        [ 7.7276e-02,  7.6082e-01, -1.9565e+00, -7.8190e-04, -3.7111e-02],\n",
      "        [-1.8489e+00, -9.9323e-01, -3.1014e-01,  3.4221e-03, -6.5762e-02],\n",
      "        [ 1.8050e-01, -2.8665e+00,  8.2338e-01,  7.1886e-04, -2.6109e+00],\n",
      "        [ 5.4308e-01,  6.5206e-01, -2.5858e+00, -4.2955e-03, -1.1528e+00],\n",
      "        [-3.5005e+00,  1.3473e-01,  7.6172e-01, -3.1266e-03,  1.5072e-01]],\n",
      "       requires_grad=True)\n",
      "encoder.0.bias Parameter containing:\n",
      "tensor([-0.0705,  0.0133, -0.2966,  4.1258, -0.5688], requires_grad=True)\n",
      "decoder.0.weight Parameter containing:\n",
      "tensor([[-2.5179,  1.1604, -0.3327, -2.0690,  1.3157,  0.3400, -2.4214,  0.3816,\n",
      "          0.6037, -1.2411],\n",
      "        [ 1.1549, -1.7554, -1.5806, -0.1982,  0.4076,  1.6696,  0.0608, -2.5154,\n",
      "          0.5243,  0.4187],\n",
      "        [-1.0577, -1.4196, -1.5565, -0.1372,  1.5106, -1.0905,  0.3921,  1.4680,\n",
      "         -1.3049,  1.2565],\n",
      "        [-2.3527,  1.2253,  1.3348,  0.1889,  1.3851, -0.4801, -0.6714, -1.6579,\n",
      "         -2.0602, -2.3657],\n",
      "        [ 0.4396, -2.3096,  1.4181, -0.0708,  0.7966,  0.6988,  1.1439, -2.4533,\n",
      "         -0.6606,  0.8089]])\n",
      "decoder.0.bias Parameter containing:\n",
      "tensor([0.5314, 1.5771, 0.4055, 2.1827, 0.3482, 0.3670, 0.4178, 1.2394, 2.0534,\n",
      "        0.3931])\n",
      "---\n",
      "encoder.0.weight Parameter containing:\n",
      "tensor([[-3.0779e+00, -1.2528e+00,  4.0658e-01, -1.0734e-03,  8.3058e-01],\n",
      "        [-2.3189e+00, -1.9536e+00,  8.1243e-01, -1.1606e-03, -7.5866e-01],\n",
      "        [-2.7281e+00, -4.2735e-01, -2.1963e+00,  2.1301e-03,  7.4523e-01],\n",
      "        [-2.0575e+00, -1.1084e+00, -3.4589e-01, -7.7982e-04, -1.1809e+00],\n",
      "        [-3.4953e-01,  5.4487e-01, -1.7092e+00, -1.2685e-03, -2.3166e+00],\n",
      "        [-6.0527e-01, -2.1070e+00, -1.7401e+00, -6.0202e-05,  1.6681e-01],\n",
      "        [ 1.1114e+00,  4.6200e-01, -6.9253e-01, -9.7844e-04, -5.0017e+00]],\n",
      "       requires_grad=True)\n",
      "encoder.0.bias Parameter containing:\n",
      "tensor([ 0.5379, -0.3465, -0.9857,  0.7269, -1.1773], requires_grad=True)\n",
      "decoder.0.weight Parameter containing:\n",
      "tensor([[-2.8812, -1.1204, -2.9408, -2.5082, -0.0932,  0.1742,  1.4747],\n",
      "        [-1.4787, -2.8363, -0.7737, -0.1328,  1.3204, -2.6357,  0.2290],\n",
      "        [ 1.1080,  1.9897, -1.3556, -0.1799, -0.3645, -1.1752, -0.0077],\n",
      "        [ 1.0971,  0.0900,  0.9784, -0.2670,  0.0406, -2.8168, -0.1874],\n",
      "        [ 1.6156,  0.1473,  1.3825, -0.3866, -0.3022,  0.4903, -1.5379]])\n",
      "decoder.0.bias Parameter containing:\n",
      "tensor([0.2884, 0.6470, 0.7973, 2.2324, 2.1754, 2.2360, 2.1867])\n",
      "---\n",
      "user_mda.encoder.0.weight Parameter containing:\n",
      "tensor([[-4.2298e+00,  2.8513e-01, -1.4298e+00,  4.3226e-04,  2.6061e-01],\n",
      "        [ 7.8817e-01, -1.0308e+00, -2.0594e+00, -1.8189e-03, -2.7300e+00],\n",
      "        [-1.3828e+00, -1.9681e+00, -1.7320e+00,  4.2058e-03,  4.7564e-01],\n",
      "        [-2.0084e+00, -9.7755e-01, -8.2517e-01, -4.5225e-05, -1.6357e+00],\n",
      "        [ 6.5722e-01, -4.5356e-02,  3.7121e-01, -1.0810e-03, -1.5999e-01],\n",
      "        [ 7.7276e-02,  7.6082e-01, -1.9565e+00, -7.8190e-04, -3.7111e-02],\n",
      "        [-1.8489e+00, -9.9323e-01, -3.1014e-01,  3.4221e-03, -6.5762e-02],\n",
      "        [ 1.8050e-01, -2.8665e+00,  8.2338e-01,  7.1886e-04, -2.6109e+00],\n",
      "        [ 5.4308e-01,  6.5206e-01, -2.5858e+00, -4.2955e-03, -1.1528e+00],\n",
      "        [-3.5005e+00,  1.3473e-01,  7.6172e-01, -3.1266e-03,  1.5072e-01]],\n",
      "       requires_grad=True)\n",
      "user_mda.encoder.0.bias Parameter containing:\n",
      "tensor([-0.0705,  0.0133, -0.2966,  4.1258, -0.5688], requires_grad=True)\n",
      "user_mda.decoder.0.weight Parameter containing:\n",
      "tensor([[-2.5179,  1.1604, -0.3327, -2.0690,  1.3157,  0.3400, -2.4214,  0.3816,\n",
      "          0.6037, -1.2411],\n",
      "        [ 1.1549, -1.7554, -1.5806, -0.1982,  0.4076,  1.6696,  0.0608, -2.5154,\n",
      "          0.5243,  0.4187],\n",
      "        [-1.0577, -1.4196, -1.5565, -0.1372,  1.5106, -1.0905,  0.3921,  1.4680,\n",
      "         -1.3049,  1.2565],\n",
      "        [-2.3527,  1.2253,  1.3348,  0.1889,  1.3851, -0.4801, -0.6714, -1.6579,\n",
      "         -2.0602, -2.3657],\n",
      "        [ 0.4396, -2.3096,  1.4181, -0.0708,  0.7966,  0.6988,  1.1439, -2.4533,\n",
      "         -0.6606,  0.8089]])\n",
      "user_mda.decoder.0.bias Parameter containing:\n",
      "tensor([0.5314, 1.5771, 0.4055, 2.1827, 0.3482, 0.3670, 0.4178, 1.2394, 2.0534,\n",
      "        0.3931])\n",
      "item_mda.encoder.0.weight Parameter containing:\n",
      "tensor([[-3.0779e+00, -1.2528e+00,  4.0658e-01, -1.0734e-03,  8.3058e-01],\n",
      "        [-2.3189e+00, -1.9536e+00,  8.1243e-01, -1.1606e-03, -7.5866e-01],\n",
      "        [-2.7281e+00, -4.2735e-01, -2.1963e+00,  2.1301e-03,  7.4523e-01],\n",
      "        [-2.0575e+00, -1.1084e+00, -3.4589e-01, -7.7982e-04, -1.1809e+00],\n",
      "        [-3.4953e-01,  5.4487e-01, -1.7092e+00, -1.2685e-03, -2.3166e+00],\n",
      "        [-6.0527e-01, -2.1070e+00, -1.7401e+00, -6.0202e-05,  1.6681e-01],\n",
      "        [ 1.1114e+00,  4.6200e-01, -6.9253e-01, -9.7844e-04, -5.0017e+00]],\n",
      "       requires_grad=True)\n",
      "item_mda.encoder.0.bias Parameter containing:\n",
      "tensor([ 0.5379, -0.3465, -0.9857,  0.7269, -1.1773], requires_grad=True)\n",
      "item_mda.decoder.0.weight Parameter containing:\n",
      "tensor([[-2.8812, -1.1204, -2.9408, -2.5082, -0.0932,  0.1742,  1.4747],\n",
      "        [-1.4787, -2.8363, -0.7737, -0.1328,  1.3204, -2.6357,  0.2290],\n",
      "        [ 1.1080,  1.9897, -1.3556, -0.1799, -0.3645, -1.1752, -0.0077],\n",
      "        [ 1.0971,  0.0900,  0.9784, -0.2670,  0.0406, -2.8168, -0.1874],\n",
      "        [ 1.6156,  0.1473,  1.3825, -0.3866, -0.3022,  0.4903, -1.5379]])\n",
      "item_mda.decoder.0.bias Parameter containing:\n",
      "tensor([0.2884, 0.6470, 0.7973, 2.2324, 2.1754, 2.2360, 2.1867])\n"
     ]
    }
   ],
   "source": [
    "for name, param in user_mda.named_parameters():\n",
    "    print(name, param)\n",
    "print(\"---\")\n",
    "for name, param in item_mda.named_parameters():\n",
    "    print(name, param)\n",
    "print(\"---\")\n",
    "for name, param in mdacf.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (star-reco)",
   "language": "python",
   "name": "starreco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
